{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees ðŸŒ²ðŸŒ³ðŸŒ´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The solutions and notes to filling out the notebook that is linked in the encounter_notes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"penguins_simple.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">Our task today: predict the species of a penguin </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to go through the workflow we've learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... and assign X and y: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# we start with two features again\n",
    "X = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Not in the notebook in CM, but adhering to our workflow, lets do a: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=Xtrain[\"Body Mass (g)\"], y=Xtrain[\"Culmen Length (mm)\"], hue=ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree from Scratch\n",
    "\n",
    "#### 4. Make one prediction for every penguin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before looking at the code: \n",
    "# think about a rule, when a penguin is likely to be an Adelie-penguin by looking at the graph.\n",
    "# We want to partition this plot into different regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once wehave one partition: we can treat each resulting region/node as a new problem space, \n",
    "# where you can ask a new question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []   #list of ypred\n",
    "for idx, row in Xtrain.iterrows(): # idx row: values of a row as a pd.Series (with column-names as index)\n",
    "    if row[\"Culmen Length (mm)\"] < 43:\n",
    "        predictions.append('Adelie')\n",
    "    else:\n",
    "        if row[\"Body Mass (g)\"] < 4500: \n",
    "            predictions.append(\"Chinstrap\")\n",
    "        else: \n",
    "            predictions.append(\"Gentoo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.scatterplot(x=Xtrain[\"Body Mass (g)\"], y=Xtrain[\"Culmen Length (mm)\"], hue=ytrain)\n",
    "#plt.axis((2500, 6500, 30, 62))\n",
    "#plt.plot([2500, 6500],[43,43], color=\"red\") #horizontal\n",
    "#plt.plot([4500, 4500],[43, 62],color=\"red\") #top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Gentoo',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie',\n",
       " 'Chinstrap',\n",
       " 'Adelie',\n",
       " 'Adelie',\n",
       " 'Gentoo',\n",
       " 'Adelie']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Calculate the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "accuracy_score(ytrain, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    " # -> no \"Learning\" yet! Only follows rules that we gave it. \n",
    "    #And we adjusted these boundaries by hand (by guessing what a better split would be) and\n",
    "    # check if we get a better accuracy.\n",
    "# But: hard to estimate, what a better split is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... but is there a better way than guessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "Yes! It's called **Gini-Impurity!**   \n",
    "It can be used to measure how good our split is -> how \"pure\" the resulting nodes are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plot = sns.scatterplot(x=Xtrain[\"Body Mass (g)\"], y=Xtrain[\"Culmen Length (mm)\"], hue=ytrain, s=150)\n",
    "plt.axis((3910, 4390, 40, 48))\n",
    "plt.plot([3910, 4390],[43.5,43.5], linewidth=2, color=\"red\") #horizontal\n",
    "plt.plot([4220, 4220],[0,43.5], linewidth=1, color=\"red\") #bottom\n",
    "plt.plot([4165, 4165],[43.5,48], linewidth=1, color=\"red\") #top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GINI =  $\\sum\\nolimits_{k=1}^K$(p$_{k}$(1 - p$_{k}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K = classes, \n",
    "p = Proportion of points belonging to class k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the bottom left node:  \n",
    "#2 Classes (K)\n",
    "#9 penguins total\n",
    "#8 orange,  \n",
    "#1 blue penguins,   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = 8/9   # p_orange\n",
    "p2 = 1/9    # p_blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini1 = (p1 * (1-p1)) + (p2 * (1- p2))\n",
    "gini1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpretation: \n",
    "#    pure node: 0\n",
    "#    the lower the gini, the better the split.\n",
    "    #    (two classes: worst Gini 0.5)\n",
    "    #    (three classes: 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bottom right:  #Best Case\n",
    "gini2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upper left:  \n",
    "p3 = 1/2\n",
    "p4 = 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini3 = (p3 * (1-p3)) + (p4 * (1- p4))\n",
    "gini3   #worst possible with wo classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upper right: \n",
    "p5 = 6/7\n",
    "p6 = 1/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini4 = (p5 * (1-p5)) + (p6 * (1- p6))\n",
    "gini4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was calculating the Gini for each node. But if we want to evaluate how good a split is /e.g. the vertical line on the top: \n",
    "# we take the weighted average of the gini of the two nodes that we get. \n",
    "#upper_left_node = 4/11\n",
    "#upper_right_node = 7/11\n",
    "gini3*(4/11)  + gini4*(7/11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and then we can move the line around and see where we get the best gini-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is what our model will do: it will move around the lines until it finds the best splits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luckily, there is a Decision Tree Model in Sklearn that will do all the hard work for us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and it finds the optimal questions and separations using the **CART Algorithm**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the Algorithm work?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For each feature, determine the best threshold for splitting\n",
    "2. Determine the best feature-threshold pair\n",
    "3. Create two child nodes\n",
    "4. Split the data points across child nodes\n",
    "5. For each node, start again from 1.\n",
    "6. If subset is pure or max_depth is reached STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = DecisionTreeClassifier(max_depth=2)\n",
    "m.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would overfitting look like? Each sample has its own node. \n",
    "# Talk a bit about the hyperparameters. This is how we regularize our model. e.g. min leaf size, max depth,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = m.predict(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Gentoo', 'Gentoo', 'Adelie', 'Gentoo', 'Gentoo', 'Chinstrap',\n",
       "       'Gentoo', 'Gentoo', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
       "       'Adelie', 'Chinstrap', 'Chinstrap', 'Adelie', 'Adelie', 'Gentoo',\n",
       "       'Gentoo', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo', 'Gentoo',\n",
       "       'Adelie', 'Chinstrap', 'Adelie', 'Gentoo', 'Adelie', 'Chinstrap',\n",
       "       'Gentoo', 'Chinstrap', 'Adelie', 'Gentoo', 'Adelie', 'Chinstrap',\n",
       "       'Adelie', 'Chinstrap', 'Gentoo', 'Adelie', 'Adelie', 'Gentoo',\n",
       "       'Adelie', 'Adelie', 'Gentoo', 'Chinstrap', 'Adelie', 'Adelie',\n",
       "       'Chinstrap', 'Adelie', 'Adelie', 'Adelie', 'Gentoo', 'Chinstrap',\n",
       "       'Gentoo', 'Adelie', 'Chinstrap', 'Gentoo', 'Adelie', 'Gentoo',\n",
       "       'Chinstrap', 'Gentoo', 'Chinstrap', 'Gentoo', 'Gentoo', 'Gentoo',\n",
       "       'Chinstrap', 'Gentoo', 'Adelie', 'Gentoo', 'Gentoo', 'Chinstrap',\n",
       "       'Gentoo', 'Adelie', 'Chinstrap', 'Chinstrap', 'Adelie', 'Gentoo',\n",
       "       'Gentoo', 'Gentoo', 'Chinstrap', 'Gentoo', 'Gentoo', 'Chinstrap',\n",
       "       'Gentoo', 'Adelie', 'Adelie', 'Chinstrap', 'Gentoo', 'Adelie',\n",
       "       'Adelie', 'Gentoo', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
       "       'Gentoo', 'Adelie', 'Gentoo', 'Gentoo', 'Adelie', 'Chinstrap',\n",
       "       'Gentoo', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo', 'Adelie',\n",
       "       'Chinstrap', 'Adelie', 'Chinstrap', 'Gentoo', 'Adelie', 'Adelie',\n",
       "       'Chinstrap', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo', 'Adelie',\n",
       "       'Adelie', 'Gentoo', 'Chinstrap', 'Chinstrap', 'Chinstrap',\n",
       "       'Adelie', 'Adelie', 'Gentoo', 'Chinstrap', 'Adelie', 'Adelie',\n",
       "       'Gentoo', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo', 'Gentoo',\n",
       "       'Gentoo', 'Adelie', 'Chinstrap', 'Gentoo', 'Gentoo', 'Chinstrap',\n",
       "       'Gentoo', 'Chinstrap', 'Adelie', 'Adelie', 'Gentoo', 'Adelie',\n",
       "       'Chinstrap', 'Adelie', 'Gentoo', 'Gentoo', 'Adelie', 'Gentoo',\n",
       "       'Chinstrap', 'Gentoo', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo',\n",
       "       'Adelie', 'Adelie', 'Adelie', 'Gentoo', 'Chinstrap', 'Gentoo',\n",
       "       'Gentoo', 'Gentoo', 'Adelie', 'Adelie', 'Gentoo', 'Adelie',\n",
       "       'Adelie', 'Adelie', 'Adelie', 'Gentoo', 'Chinstrap', 'Adelie',\n",
       "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Chinstrap',\n",
       "       'Chinstrap', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo',\n",
       "       'Chinstrap', 'Chinstrap', 'Adelie', 'Gentoo', 'Chinstrap',\n",
       "       'Gentoo', 'Gentoo', 'Adelie', 'Adelie', 'Adelie', 'Adelie',\n",
       "       'Chinstrap', 'Adelie', 'Gentoo', 'Adelie', 'Adelie', 'Gentoo',\n",
       "       'Gentoo', 'Adelie', 'Adelie', 'Gentoo', 'Chinstrap', 'Gentoo',\n",
       "       'Adelie', 'Gentoo', 'Gentoo', 'Adelie', 'Adelie', 'Chinstrap',\n",
       "       'Chinstrap', 'Gentoo', 'Chinstrap', 'Chinstrap', 'Adelie',\n",
       "       'Adelie', 'Gentoo', 'Gentoo', 'Adelie', 'Chinstrap', 'Gentoo',\n",
       "       'Gentoo', 'Gentoo', 'Gentoo', 'Gentoo', 'Chinstrap', 'Adelie',\n",
       "       'Chinstrap', 'Adelie', 'Adelie', 'Gentoo', 'Adelie', 'Gentoo',\n",
       "       'Adelie', 'Chinstrap', 'Adelie', 'Adelie', 'Gentoo', 'Adelie'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.predict(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.score(Xtrain, ytrain)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.predict_proba(Xtrain)  \n",
    "# all the same probability for samples in the same node. More like a \"confidence value\" based on class frequencies in the node.\n",
    "# fraction of samples of the same class in a leaf -> adds up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'random_state : int, RandomState instance or None, default=None\\n    Controls the randomness of the estimator. The features are always\\n    randomly permuted at each split, even if ``splitter`` is set to\\n    ``\"best\"``. When ``max_features < n_features``, the algorithm will\\n    select ``max_features`` at random at each split before finding the best\\n    split among them. But the best found split may vary across different\\n    runs, even if ``max_features=n_features``. That is the case, if the\\n    improvement of the criterion is identical for several splits and one\\n    split has to be selected at random. To obtain a deterministic behaviour\\n    during fitting, ``random_state`` has to be fixed to an integer.\\n    See :term:`Glossary <random_state>` for details.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is always randomness in a Decision Tree (as it is implemented by sklearn): from the docu: \n",
    "\"\"\"random_state : int, RandomState instance or None, default=None\n",
    "    Controls the randomness of the estimator. The features are always\n",
    "    randomly permuted at each split, even if ``splitter`` is set to\n",
    "    ``\"best\"``. When ``max_features < n_features``, the algorithm will\n",
    "    select ``max_features`` at random at each split before finding the best\n",
    "    split among them. But the best found split may vary across different\n",
    "    runs, even if ``max_features=n_features``. That is the case, if the\n",
    "    improvement of the criterion is identical for several splits and one\n",
    "    split has to be selected at random. To obtain a deterministic behaviour\n",
    "    during fitting, ``random_state`` has to be fixed to an integer.\n",
    "    See :term:`Glossary <random_state>` for details.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = plot_tree(m, feature_names=[\"Body Mass\", \"Culmen Length\"], class_names=[\"Adelie\", \"Chinstrap\", \"Gentoo\"], filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = DecisionTreeClassifier(max_depth=3)\n",
    "m2.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "t2 = plot_tree(m2, feature_names = [\"Body Mass\", \"Culmen Length\"], class_names=[\"Ade\", \"Chin\", \"Gen\"], filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the order? As we give the features to the model. \n",
    "list(zip(m.feature_importances_, Xtrain.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why is it splitting the left inner node again? \n",
    "#-> to be more certain\n",
    "#-> the Algorithm wants to split until the nodes are pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When should I use a Decision tree? \n",
    "In general, there is a Classification Tree-model and one for Regression in sklearn.     \n",
    "But: Decision Trees on their own are usually not great -> better: Random Forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages:** \n",
    "- intuitive understanding, can be visualized\n",
    "- requires little data preparation (e.g. no normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disadvantages:**\n",
    "- prone to overfitting (especially with large number of features)  \n",
    "- unstable on their own "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we spent the whole evening on these trees and now I am telling you they basically suck.. \n",
    "# BUT: they can be made a lot better if we let them work together. And we see how that works tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
