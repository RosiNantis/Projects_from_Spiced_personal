{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b481b94a",
   "metadata": {},
   "source": [
    "## Using BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c86cae0",
   "metadata": {},
   "source": [
    "BeautifulSoup is a library which parses HTML and creates a tree structure of python objects that we can navigate through, extract information from, and edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5682db35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!conda install -y bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d2afb",
   "metadata": {},
   "source": [
    "#### Convert the raw HTML string to a BeautifulSoup object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28ab01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a40f9a",
   "metadata": {},
   "source": [
    "### Task 1: Extract the poem titles, url and poems with Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b1f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_url(url): \n",
    "    import os\n",
    "    import time\n",
    "    \"\"\"\n",
    "    search_url is a function that accepts as parameter a url string\n",
    "    and then returns a text file named as text with the web page\n",
    "    requested. \n",
    "    It prints in the excecustion if the code is corectly downloaded.\n",
    "    It uses request package!\n",
    "    \"\"\"                                                                                               \n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    response = requests.get(url, headers=header)\n",
    "    time.sleep(3)\n",
    "    print(f'The status code is: {response.status_code}')\n",
    "    filename = f\"response_files/response.txt\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(response.text)\n",
    "    text = response.text\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d22d3e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_songs(class_of,saving,artist):\n",
    "    \"\"\"\n",
    "    Makes a Data Frame with the title, url, and lyrics as columns.\n",
    "    As parameter you have to include the class of the list of songs on the url.\n",
    "    Be careful about the number of \\n in the title and extract them.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    \n",
    "    all_song_titles = soup.find_all(class_= class_of)\n",
    "    all_song_titles\n",
    "    titles = []\n",
    "    for title in all_song_titles:\n",
    "        titles.append(title.a.text.split('\\n')[0].strip()) \n",
    "    # Extract all links\n",
    "    links = []\n",
    "    songlinks = soup.find_all(class_= class_of)\n",
    "    for link in songlinks:\n",
    "        links.append(link.a['href'])\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({'title':titles,'links':links})\n",
    "    df['artist'] = artist\n",
    "    df['song_lyric'] = 'blank'\n",
    "    for i in range(len(df.links[:])):\n",
    "        try:\n",
    "            lyric = BeautifulSoup(requests.get(df.links[i]).text,)\n",
    "            df['song_lyric'][i] = lyric.find('p',attrs={'class':'song-lyrics'}).text\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            continue\n",
    "    if saving == True:\n",
    "        import os\n",
    "        for i in range(len(df.song_lyric[:])):\n",
    "            filename = f\"response_files/lyrics/{df.title[i]}.txt\"\n",
    "            os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "            with open(filename,'w') as f:\n",
    "                f.write(df.song_lyric[i])\n",
    "                f.close()\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "607f1090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The status code is: 200\n",
      "The status code is: 200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = search_url('https://lyrics.az/bob-dylan/allalbums.html')\n",
    "soup = BeautifulSoup(text,'html.parser')\n",
    "df1 = find_songs('mt-3 col-sm-9 col-12 list-group mt-sm-0',True,'bob_dylan')\n",
    "\n",
    "text = search_url('https://lyrics.az/eminem/allalbums.html')\n",
    "soup = BeautifulSoup(text,'html.parser')\n",
    "df2 = find_songs('mt-3 col-sm-9 col-12 list-group mt-sm-0',True,'eminem')\n",
    "\n",
    "# text = search_url('https://lyrics.az/simon-and-garfunkel/allsongs.html')\n",
    "# soup = BeautifulSoup(text,'html.parser')\n",
    "# df3 = find_songs('px-0 mx-0 mb-5 col-12 col-sm-6 table-responsive',True,'simon&granfunkel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data workspace!\n",
    "import os  \n",
    "os.makedirs('save_frames_artists', exist_ok=True)  \n",
    "df1.to_csv('save_frames_artists/bob_dylan.csv') \n",
    "df2.to_csv('save_frames_artists/eminem.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ba6648",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26306046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba76f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vect_fit_transf(sample, df): # sample is the df.song_lyric[:2]\n",
    "    vectorizer = CountVectorizer(stop_words='english',max_df=0.8)#,ngram_range=(1, 2))\n",
    "    X = vectorizer.fit_transform(sample)\n",
    "    X_df = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names(),index = df['artist'])\n",
    "    y_df = df.artist\n",
    "\n",
    "    return X_df , y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How can we remove the most common words?\n",
    "\n",
    "* Using a list of stop words\n",
    "* Removing the words that appear in more than X% of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df , y_df =vect_fit_transf(df1.song_lyric[:],df1)\n",
    "X_dfb , y_dfb =vect_fit_transf(df2.song_lyric[:],df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab39263",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.shape, y_df.shape\n",
    "X_dfb.shape, y_dfb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d35d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a53ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab70eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "c = Counter(X_df)\n",
    "print(c.most_common(3))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb3725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff11e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=None)\n",
    "X = vectorizer.fit_transform(df1.song_lyric[:])\n",
    "X_df = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names(), index=df1['artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff11e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=None)\n",
    "Xb = vectorizer.fit_transform(df2.song_lyric[:])\n",
    "X_dfb = pd.DataFrame(Xb.todense(), columns=vectorizer.get_feature_names(), index=df2['artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20edfc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc3379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dfb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb1d8d5",
   "metadata": {},
   "source": [
    "# Explore Data Analysis\n",
    "1. $\\color{blue}{\\text{Clean data}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d05a016",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.dropna()\n",
    "X_dfb.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c258d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_df.shape), print(y_df.shape)\n",
    "print(X_dfb.shape), print(y_dfb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b816a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.reset_index(['artist'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538633a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dfb.reset_index(['artist'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e1d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df[\"and\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd1437",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "X_df['1910'].hist(figsize=(12,6), density=True, bins=10)\n",
    "plt.title('Histogram for df.Speed')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Relative frequency of the values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5534544",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.square(X_df).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd79261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "print(operator.itemgetter(*np.argsort(model.coef_[0]))(vectorizer.get_feature_names())[-20:])\n",
    "print(operator.itemgetter(*np.argsort(model.coef_[0]))(vectorizer.get_feature_names())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5592b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
