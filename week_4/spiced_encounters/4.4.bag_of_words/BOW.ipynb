{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words (Or: *What is unique about working with text*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Goal: create a feature matrix `X` for your lyrics corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: How is text different from the types of data you've seen so far?\n",
    "* Often has to be extracted/scraped.\n",
    "* Unstructured.\n",
    "* Ambiguity.\n",
    "* Can be user-entered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: What does this mean for how you can work with text compared to types of data you've worked with so far?\n",
    "* We have to turn into numbers (feature engineering / vectorization)\n",
    "* We have to clean / preprocess it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main aspect of working with text that helps us feed it into computers / machine learning models:\n",
    "1. Data/text preprocessing\n",
    "2. Turning text into features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: Things we may want to do to clean our textual data:\n",
    "* separate words (_tokenization_), deal with spaces, new lines, etc.\n",
    "* deal with user-entered input (see e.g. https://github.com/seatgeek/thefuzz)\n",
    "* remove most frequent words (\"stop words\")\n",
    "    * using a list of words to remove\n",
    "    * removing words that appear in more than X% of the documents\n",
    "* remove special characters, punctuation, emojis \n",
    "* deal with capitalization\n",
    "* reducing words to their base parts:\n",
    "    * _stemming_\n",
    "    * _lemmatization_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization: \n",
    "* splitting text into _tokens_\n",
    "* most often words, could also be sentences, sometimes individual letters\n",
    "* .split(), regex, nltk (treebank tokenizer), scikit-learn, spacy, keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming:\n",
    "* reducing the word to a more basic form, a _stem_\n",
    "* by removing suffixes (-able, -ed, -ing)\n",
    "* nltk\n",
    "* based on heuristics / rules\n",
    "* does not have to result in a word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization:\n",
    "* reducing the work to a more basic form, a _lemma_\n",
    "* based on morphology of a word (vocabulary/dictionary)\n",
    "* nltk (wordnet lemmatizer), spacy\n",
    "* returns a word\n",
    "* it doesn't always result in a reduced form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"we all love a yellow submarine\",             # Beatles\n",
    "          \"yesterday, my submarine was in love\",        # Beatles\n",
    "          \"we are love trouble with loyalty here\",      # Eminem\n",
    "          \"loyalty to us is worth more than love is\"]   # Eminem\n",
    "labels = ['Beatles'] * 2 + ['Eminem'] * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Turning text into features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: Once you have your data cleaned and preprocessed like this, what can you imagine using as your features?\n",
    "* word counts\n",
    "* length of text\n",
    "* number of words starting with each letter\n",
    "* repetitions: # per song, length of the longest\n",
    "* number of unique words\n",
    "* average of length of words in a song\n",
    "* rule-based sentiment analysis\n",
    "* count of slang/swear/domain words in a song"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words\n",
    "\n",
    "Each token/word is a column/feature.\n",
    "* word order lost\n",
    "* large sparse matrix\n",
    "* counts not normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x20 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 26 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 15)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 18)\t1\n",
      "  (0, 9)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 19)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 14)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 15)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 16)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 2)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 6)\t1\n",
      "  (3, 11)\t1\n",
      "  (3, 13)\t1\n",
      "  (3, 4)\t2\n",
      "  (3, 17)\t1\n",
      "  (3, 7)\t1\n",
      "  (3, 10)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "        [0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 2, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names(), index=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>are</th>\n",
       "      <th>here</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>loyalty</th>\n",
       "      <th>more</th>\n",
       "      <th>my</th>\n",
       "      <th>submarine</th>\n",
       "      <th>than</th>\n",
       "      <th>to</th>\n",
       "      <th>trouble</th>\n",
       "      <th>us</th>\n",
       "      <th>was</th>\n",
       "      <th>we</th>\n",
       "      <th>with</th>\n",
       "      <th>worth</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yesterday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Beatles</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beatles</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         all  are  here  in  is  love  loyalty  more  my  submarine  than  to  \\\n",
       "Beatles    1    0     0   0   0     1        0     0   0          1     0   0   \n",
       "Beatles    0    0     0   1   0     1        0     0   1          1     0   0   \n",
       "Eminem     0    1     1   0   0     1        1     0   0          0     0   0   \n",
       "Eminem     0    0     0   0   2     1        1     1   0          0     1   1   \n",
       "\n",
       "         trouble  us  was  we  with  worth  yellow  yesterday  \n",
       "Beatles        0   0    0   1     0      0       1          0  \n",
       "Beatles        0   0    1   0     0      0       0          1  \n",
       "Eminem         1   0    0   1     1      0       0          0  \n",
       "Eminem         0   1    0   0     0      1       0          0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How can we remove the most common words?\n",
    "\n",
    "* Using a list of stop words\n",
    "* Removing the words that appear in more than X% of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X_df = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names(), index=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>love</th>\n",
       "      <th>loyalty</th>\n",
       "      <th>submarine</th>\n",
       "      <th>trouble</th>\n",
       "      <th>worth</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yesterday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Beatles</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beatles</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         love  loyalty  submarine  trouble  worth  yellow  yesterday\n",
       "Beatles     1        0          1        0      0       1          0\n",
       "Beatles     1        0          1        0      0       0          1\n",
       "Eminem      1        1          0        1      0       0          0\n",
       "Eminem      1        1          0        0      1       0          0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_df=0.8)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X_df = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names(), index=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>are</th>\n",
       "      <th>here</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>loyalty</th>\n",
       "      <th>more</th>\n",
       "      <th>my</th>\n",
       "      <th>submarine</th>\n",
       "      <th>than</th>\n",
       "      <th>to</th>\n",
       "      <th>trouble</th>\n",
       "      <th>us</th>\n",
       "      <th>was</th>\n",
       "      <th>we</th>\n",
       "      <th>with</th>\n",
       "      <th>worth</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yesterday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Beatles</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beatles</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         all  are  here  in  is  loyalty  more  my  submarine  than  to  \\\n",
       "Beatles    1    0     0   0   0        0     0   0          1     0   0   \n",
       "Beatles    0    0     0   1   0        0     0   1          1     0   0   \n",
       "Eminem     0    1     1   0   0        1     0   0          0     0   0   \n",
       "Eminem     0    0     0   0   2        1     1   0          0     1   1   \n",
       "\n",
       "         trouble  us  was  we  with  worth  yellow  yesterday  \n",
       "Beatles        0   0    0   1     0      0       1          0  \n",
       "Beatles        0   0    1   0     0      0       0          1  \n",
       "Eminem         1   0    0   1     1      0       0          0  \n",
       "Eminem         0   1    0   0     0      1       0          0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of single tokens, we now also count token pairs (bigrams), triplets (trigrams), etc.\n",
    "* preserves local word order\n",
    "* even larger, sparses matrix\n",
    "* too many features:\n",
    "    * remove high frequency n-grams (max_df): not very informative\n",
    "    * remove low frequency n-grams (min_df): very rare n-grams; can lead to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X_df = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names(), index=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>all love</th>\n",
       "      <th>are</th>\n",
       "      <th>are love</th>\n",
       "      <th>here</th>\n",
       "      <th>in</th>\n",
       "      <th>in love</th>\n",
       "      <th>is</th>\n",
       "      <th>is worth</th>\n",
       "      <th>love</th>\n",
       "      <th>...</th>\n",
       "      <th>we all</th>\n",
       "      <th>we are</th>\n",
       "      <th>with</th>\n",
       "      <th>with loyalty</th>\n",
       "      <th>worth</th>\n",
       "      <th>worth more</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yellow submarine</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yesterday my</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Beatles</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beatles</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         all  all love  are  are love  here  in  in love  is  is worth  love  \\\n",
       "Beatles    1         1    0         0     0   0        0   0         0     1   \n",
       "Beatles    0         0    0         0     0   1        1   0         0     1   \n",
       "Eminem     0         0    1         1     1   0        0   0         0     1   \n",
       "Eminem     0         0    0         0     0   0        0   2         1     1   \n",
       "\n",
       "         ...  we all  we are  with  with loyalty  worth  worth more  yellow  \\\n",
       "Beatles  ...       1       0     0             0      0           0       1   \n",
       "Beatles  ...       0       0     0             0      0           0       0   \n",
       "Eminem   ...       0       1     1             1      0           0       0   \n",
       "Eminem   ...       0       0     0             0      1           1       0   \n",
       "\n",
       "         yellow submarine  yesterday  yesterday my  \n",
       "Beatles                 1          0             0  \n",
       "Beatles                 0          1             1  \n",
       "Eminem                  0          0             0  \n",
       "Eminem                  0          0             0  \n",
       "\n",
       "[4 rows x 43 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stands for `term frequency - inverse document frequency` and aims to address the popularity/frequency of words in a corpus(not just inside of a single document)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TF = term frequency \n",
    "\n",
    "$TF(t, d)$ - frequency of term (n-gram) _t_ in document _d_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IDF(t) = inverse document frequency (of term _t_ in the whole corpus)\n",
    "\n",
    "$$ IDF(t) = \\log \\frac{1+N}{1+N_t}+1 $$\n",
    "\n",
    "Where $N$ is the number of documents\n",
    "\n",
    "and $N_t$ is the number of documents in which term $t$ appears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If term $t$ doesn't appear in many documents: $IDF(t)$ is \"large\"\n",
    "\n",
    "If term $t$ appears in many documents: $IDF(t)$ is \"small\", i.e. it is close to 1.\n",
    "\n",
    "-> terms that are too common are penalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ TFIDF(t, d) = TF(t,d)*IDF(t) $ \n",
    "\n",
    "**Q**: What kind of terms will have high TF-IDF?\n",
    "* Those that appear a lot in a small number of documents (songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X_df = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names(), index=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>are</th>\n",
       "      <th>here</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>loyalty</th>\n",
       "      <th>more</th>\n",
       "      <th>my</th>\n",
       "      <th>submarine</th>\n",
       "      <th>than</th>\n",
       "      <th>to</th>\n",
       "      <th>trouble</th>\n",
       "      <th>us</th>\n",
       "      <th>was</th>\n",
       "      <th>we</th>\n",
       "      <th>with</th>\n",
       "      <th>worth</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yesterday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Beatles</th>\n",
       "      <td>0.533343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533343</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beatles</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452035</td>\n",
       "      <td>0.356389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425802</td>\n",
       "      <td>0.425802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222201</td>\n",
       "      <td>0.335707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335707</td>\n",
       "      <td>0.425802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eminem</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.635837</td>\n",
       "      <td>0.165903</td>\n",
       "      <td>0.250651</td>\n",
       "      <td>0.317919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317919</td>\n",
       "      <td>0.317919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              all       are      here        in        is      love   loyalty  \\\n",
       "Beatles  0.533343  0.000000  0.000000  0.000000  0.000000  0.278320  0.000000   \n",
       "Beatles  0.000000  0.000000  0.000000  0.452035  0.000000  0.235891  0.000000   \n",
       "Eminem   0.000000  0.425802  0.425802  0.000000  0.000000  0.222201  0.335707   \n",
       "Eminem   0.000000  0.000000  0.000000  0.000000  0.635837  0.165903  0.250651   \n",
       "\n",
       "             more        my  submarine      than        to   trouble  \\\n",
       "Beatles  0.000000  0.000000   0.420493  0.000000  0.000000  0.000000   \n",
       "Beatles  0.000000  0.452035   0.356389  0.000000  0.000000  0.000000   \n",
       "Eminem   0.000000  0.000000   0.000000  0.000000  0.000000  0.425802   \n",
       "Eminem   0.317919  0.000000   0.000000  0.317919  0.317919  0.000000   \n",
       "\n",
       "               us       was        we      with     worth    yellow  yesterday  \n",
       "Beatles  0.000000  0.000000  0.420493  0.000000  0.000000  0.533343   0.000000  \n",
       "Beatles  0.000000  0.452035  0.000000  0.000000  0.000000  0.000000   0.452035  \n",
       "Eminem   0.000000  0.000000  0.335707  0.425802  0.000000  0.000000   0.000000  \n",
       "Eminem   0.317919  0.000000  0.000000  0.000000  0.317919  0.000000   0.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you say about the values in your new `X_df` (think about sums, normalizations, etc.)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Beatles    1.0\n",
       "Beatles    1.0\n",
       "Eminem     1.0\n",
       "Eminem     1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(X_df).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BONUS: extracting most predictive words for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```import operator\n",
    "model = LogisticRegression()\n",
    "print(operator.itemgetter(*np.argsort(model.coef_[0]))(vectorizer.get_feature_names())[-20:])\n",
    "print(operator.itemgetter(*np.argsort(model.coef_[0]))(vectorizer.get_feature_names())[:20])```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
