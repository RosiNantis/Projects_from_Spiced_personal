{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CNN-Architecture-over-a-timeline](https://www.aismartz.com//blog/wp-content/uploads/2019/10/CNN-Architecture-over-a-timeline.jpg)\n",
    "\n",
    "https://www.aismartz.com/blog/cnn-architectures/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ WHAT?\n",
    "    + it is a network which was trained on a large dataset on a large-scale-image classification Task. One can usit as it is for image classification or for transfer learning so we can custumise the model for a new task\n",
    "    \n",
    "+ BENEFITS\n",
    "    + we don't have to train the model\n",
    "    + very easy to incorporate \n",
    "    + fast simulation\n",
    "    + we can achieve very good performaces\n",
    "    \n",
    "+ EXAMPLE\n",
    " + U net: recognize feature on medical images\n",
    " + MobileNet\n",
    " + VGG16/19\n",
    " + ResNet\n",
    " + InceptionV3\n",
    " \n",
    " [1000 different classes](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a) that were used from the [Imagenet](https://www.image-net.org/update-mar-11-2021.php) dataset for training some of the pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, decode_predictions, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image # Keras own inbuild image class\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load image from internet that belong under any of the 1000 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert image to array, can also specify datatype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot image \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#show model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/preprocess_input\n",
    "img = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check shape required by model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expand dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape of pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# decode labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's have a look at the output of an intermediate convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose your intermediate convolution layer to visualize the output at that layer\n",
    "layer_name = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial input:\n",
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to our chosen layer:\n",
    "model.get_layer(layer_name).input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output = model.get_layer(layer_name).output\n",
    "layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_model = keras.models.Model(inputs=model.input, outputs=layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature map:\n",
    "feature_map=intermediate_model.predict(img)\n",
    "feature_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(feature_map[0,:,:,63])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning for Neural Networks\n",
    "\n",
    "> Transfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem. For instance, features from a model that has learned to identify racoons may be useful to kick-start a model meant to identify tanukis (japanese racoons).\n",
    "\n",
    "__The benefits of transfer learning are:__\n",
    "* you can reuse pre-trained networks\n",
    "* it saves lots of training time\n",
    "* it allows you to train with very small training datasets\n",
    "\n",
    "__Procedure__\n",
    "1. Take the weights and architecture of a [pre-trained network](https://keras.io/api/applications/)\n",
    "2. Load the \"convolutional base\" of the model (everything except the final dense layers)\n",
    "3. Freeze all the layers of the base (weights become fixed)\n",
    "4. Add a fully connected dense layer on top\n",
    "5. **Add a task specific dense output layer**\n",
    "6. Compile and fit the model to your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images into `keras`\n",
    "Keras has its own in build Objects and Methods to get image data in efficiently\n",
    "See: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image\n",
    "\n",
    "- `class ImageDataGenerator`: Generate batches of tensor image data with **optional** real-time data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder names containing images of the things you want to classify\n",
    "\n",
    "# plug in the path to your data folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an image data generator\n",
    "data_gen = image.ImageDataGenerator(\n",
    "    # define the preprocessing function that should be applied to all images\n",
    "    preprocessing_function=preprocess_input,\n",
    "     #rotation_range=45,\n",
    "     #width_shift_range=0.2,\n",
    "     #height_shift_range=0.2,\n",
    "     #horizontal_flip=True, \n",
    "     #vertical_flip=True,\n",
    "    #zoom_range=0.2,\n",
    "    # shear_range=0.2    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a generator that returns batches of X and y arrays\n",
    "train_data_gen = data_gen.flow_from_directory(\n",
    "        directory=base_path,\n",
    "        class_mode=\"categorical\",\n",
    "        classes=classes,\n",
    "        batch_size=30,\n",
    "        target_size=(224, 224)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all images at once\n",
    "xtrain, ytrain = next(train_data_gen)\n",
    "xtrain.shape, ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(6, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImages(xtrain)\n",
    "print(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ytrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Select the convolutional base "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Freeze the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze it!\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Add your own dense layers on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(len(classes), activation='softmax')) #!!! Final layer with a length of 2, and softmax activation \n",
    "# have a look at the trainable and non-trainable params statistic\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compile and train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=keras.losses.categorical_crossentropy,\n",
    "              metrics=[keras.metrics.categorical_accuracy])\n",
    "\n",
    "# observe the validation loss and stop when it does not improve after 3 iterations\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(xtrain, ytrain, \n",
    "          epochs=50, \n",
    "          verbose=2,\n",
    "          callbacks=[callback],\n",
    "          # use 30% of the data for validation\n",
    "          validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5. Use it to predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img('object.png',target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = image.img_to_array(img,dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = preprocess_input(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.expand_dims(a, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(a)[0].round(decimals = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = classes, height = model.predict(a)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6. Save your model for later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/wallet_phone.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Advanced Optional Step: Fine Tuning\n",
    "\n",
    "This is done after the initial training! Adapt a few of the base layers to the specific learning task by retraining the model. This can improve accuracy, especially if the original learning task of the pre-trained model differs a lot from the actual task.\n",
    "\n",
    "1. Unfreeze some (or all) of the layers in the convolutional base (starting with the base output layer)\n",
    "2. Recompile your model and choose a very low learning rate (`1e-5`)\n",
    "2. Continue training the model but stop early to avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Advanced: Data augmentation)\n",
    "\n",
    "> https://keras.io/guides/transfer_learning/\n",
    "\n",
    "> https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "\n",
    "Applies random distortions and transformations to the images (only on your training data!). You need to store your training and validation data at separate locations and use a second `ImageDataGenerator` for your validation data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our project: How to continue!\n",
    "\n",
    "1. Have image data in the categories we want to classify: check\n",
    "2. Have a model to use:\n",
    "    - One or several pre-trained models\n",
    "    - Train your own with transfer learning <-- will probably have the best performance\n",
    "    - Take the challenge and train your own from scratch\n",
    "4. Test on your data, evaluate, reflect\n",
    "\n",
    "5. Save the model(s)\n",
    "\n",
    "6. Load the trained model into `predict.py` (the modified `capture.py` with the `predict_frame(frame)` function) \n",
    "\n",
    "\n",
    "- If you don't have it yet, write a fuction `predict_frame(frame)` that uses the trained model to predict the object in the current frame. It should return a dictionary of class probabilities and names.\n",
    "    - make sure that the input image to the model is of size (224, 224)\n",
    "- Modify the script such that it makes a prediction once you press the `p` key\n",
    "- Write the prediction as a log message to the terminal\n",
    "\n",
    "### Advanced\n",
    "\n",
    "- Display the result of the prediction on the current webcam frame\n",
    "- Make an automatic prediction every second (Hint: the `while` loop has a speed of approx. 30 frames per second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the entire images and labels into arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore the data folder\n",
    "base_path = 'data/'\n",
    "\n",
    "# Let's define the classes\n",
    "classes = os.listdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for class_ in classes:\n",
    "        print(class_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(base_path):\n",
    "    \"\"\"it loads all the image into X and the classes in y \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    classes = os.listdir(base_path)\n",
    "    for class_ in classes:\n",
    "        \n",
    "        files = os.listdir(base_path+class_)\n",
    "        for file in files:\n",
    "            pic = image.load_img(path=base_path+class_+'/'+f'{file}',target_size=(224,224))\n",
    "            numpy_image = np.array(pic)\n",
    "            processed_image = preprocess_input(numpy_image)\n",
    "            X_list.append(processed_image)\n",
    "            y_list.append(class_)\n",
    "        \n",
    "    X = np.array(X_list)\n",
    "    y = np.array(y_list)\n",
    "    \n",
    "    return X, y, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,classes= load_image(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\"wallet\":0, \"phone\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.vectorize(my_dict.get)(y)\n",
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
