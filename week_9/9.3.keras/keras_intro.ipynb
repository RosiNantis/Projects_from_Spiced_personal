{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras/TensorFlow\n",
    "\n",
    "Keras is an API. \n",
    "\n",
    "remember: An API (Application Programming Interface), is ... intermediary software that facilitates communication between 2 other pieces of software. ([Course material 6.1.1.](https://krspiced.pythonanywhere.com/chapters/project_pipeline/api/README.html?highlight=api#what-is-an-api))\n",
    "\n",
    "Keras \"connects\" python with TensorFlow.  \n",
    "\n",
    "Tensorflow is the platform we use to work with neural networks. It uses dataflow graphs ([think about back and forward propagation](https://colah.github.io/posts/2015-08-Backprop/)). It is written in Cuda (a parallel computing platform working on GPUs) and C++ for performance.\n",
    "\n",
    "Keras (https://keras.io/about/) is a deep learning API written in Python to handle several backends (TensorFlow, Microsoft Cognitiv Toolkit, Theano). Since TensorFlow 1.4 it is part of TensorFlow. It was developed with a focus on enabling fast experimentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a tensor?\n",
    "etymological origin: tension => stress/strain (in 3D structures)\n",
    "\n",
    "![image](figures/ranks.jpg)\n",
    "\n",
    "It's an n dimensional object, which can contain the weights of the different layers, activation functions, etc., etc., ... (any python object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.6.2\n",
      "Keras Version: 2.6.0\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "# what I needed to do/install after \"conda create -n tensor\":\n",
    "\n",
    "# conda activate tensor\n",
    "# sudo apt install python3-pip\n",
    "# pip install --upgrade pip\n",
    "# pip install tensorflow\n",
    "# pip install opencv-python\n",
    "# pip install jupyter\n",
    "# pip install sklearn\n",
    "# pip install matplotlib\n",
    "# pip install pandas\n",
    "\n",
    "# (my versions in 'tensor'-env: python: 3.8.10, tensorflow/keras: 2.7.0)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'scalar' has 0 dimensions and a shape of ().\n",
      "'vector' has 1 dimension and a shape of (4,).\n",
      "'matrix' has 2 dimensions and a shape of (2, 3).\n",
      "'tensor3' has 3 dimensions and a shape of (2, 4, 3).\n",
      "'tensor7' has 7 dimensions and a shape of (3, 2, 4, 7, 1, 2, 9).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scalar = np.array(6)\n",
    "\n",
    "vector = np.array([7, 2, 9, 10])\n",
    "\n",
    "matrix = np.array([[5.2, 3.0, 4.5],[9.1, 0.1, 0.3]])\n",
    "\n",
    "tensor3 = np.array([[[1,4,7], [2,9,7], [1,3,0], [9,6,9]], [[2,3,4], [4,3,5], [7,7,2], [3, 9, 8]]])\n",
    "\n",
    "tensor7 = np.random.rand(3,2,4,7,1,2,9)\n",
    "\n",
    "print(f'\\'scalar\\' has {scalar.ndim} dimensions and a shape of {scalar.shape}.')\n",
    "print(f'\\'vector\\' has {vector.ndim} dimension and a shape of {vector.shape}.')\n",
    "print(f'\\'matrix\\' has {matrix.ndim} dimensions and a shape of {matrix.shape}.')\n",
    "print(f'\\'tensor3\\' has {tensor3.ndim} dimensions and a shape of {tensor3.shape}.')\n",
    "print(f'\\'tensor7\\' has {tensor7.ndim} dimensions and a shape of {tensor7.shape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your notebook or the dependencies create problems, you can try using [Google colab](https://colab.research.google.com) (login required). Many students use it for their final project. Be aware of time limits (and save intermediate results).\n",
    "\n",
    "[tensorflow playground](https://playground.tensorflow.org)\n",
    "\n",
    "[activation functions](https://himanshuxd.medium.com/activation-functions-sigmoid-relu-leaky-relu-and-softmax-basics-for-neural-networks-and-deep-8d9c70eed91e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Challenge\"\n",
    "Assume you have this labeled data (color codes according to the two half moons). \n",
    "![moon problem](figures/moons.png)\n",
    "Task: Predict, whether an arbitrary new point belongs to the upper or to the lower half moon.  \n",
    "What information do we have as input?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipe to Building and Artificial Neural Network \n",
    "\n",
    "1. **configure a model, give**:\n",
    "    + architecture\n",
    "    + number of neurons\n",
    "    + layers\n",
    "    + type of activation functions\n",
    "    \n",
    "2. **compile the model, give**:\n",
    "    + optimizers (algorithm that finds the minimum of the loss function)\n",
    "    + loss function (the loss function to be optimized; we choose the loss function depending on the problem we are solving)\n",
    "    + metrics (metrics to be tracked over training)\n",
    "    \n",
    "3. **fitting the model, give**:\n",
    "    + epochs (number of iterations of the dataset in training)\n",
    "    + batch size (the data is fed in batches; not all data at once)\n",
    "    + Determines which fraction of the data is used as a validation set \n",
    "    \n",
    "    \n",
    "4. Evaluate  \n",
    "\n",
    "5. Make predictions  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple configuration\n",
    "\n",
    "Individual dense layers mapped one by one. Different types of layers are described [here](https://towardsdatascience.com/four-common-types-of-neural-network-layers-c0d3bb2a966c), e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "K.clear_session()\n",
    "    \n",
    "# run this as soon as you want to restart creating a model!\n",
    "\n",
    "model = tf.keras.models.Sequential() \n",
    "\n",
    "# in case your system is not configured to support GPUs, you might get a warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's define the first layer**  \n",
    "- units: number of neurons\n",
    "\n",
    "- input_dim: dimensions (in our example: 2) of input tensor without bias (X[:,0], X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Where did 12 parameters in the first layer come from? Think about the architecture.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first layer, 2 inputs (same for each) and 1 separate bias for each neuron. \n",
    "\n",
    "In the second layer, the weights for the  4 outputs of the 1st layer and 1 bias  goes to the remaining neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(\"figures/network.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compilation\n",
    "\n",
    "This is where Keras actually communicates with TensorFlow\n",
    "and creates what's called a 'computation graph'. Keras is compiling\n",
    "our model into a very abstract form that is implemented in C++.\n",
    "\n",
    "One caveat about compile -- if you run this piece of code more than once in a single session, Keras will get confused.\n",
    "\n",
    "\n",
    "Running Keras in Jupyter is fine, but **remember**:\n",
    "\n",
    "    `from tensforflow.keras import backend as K\n",
    "     K.clear_session()` \n",
    "\n",
    "You should do this everytime you use Keras, because it will clear the memory of the previously compiled model every time.\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model.compile(\n",
    "              , # the algorithm used to optimize the weights\n",
    "              , # how the loss is quantified (real values)\n",
    "              , # how good the model performs (not used by opt. algorithm)\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Some nice [explanation](https://towardsdatascience.com/a-look-at-gradient-descent-and-rmsprop-optimizers-f77d483ef08b) of optimizers like [Adam](https://keras.io/api/optimizers/adam/)\n",
    "    \n",
    "ADAM optimises the network using a stochastic gradient descent. It is mentioned in the documentation that it works well if the sample size is larger in comparison to the number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder: Stochastic gradient descent tries to minimise the gradient of the loss function using randomly chosen mini-batches.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit the model to training data\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size: Number of samples per gradient update.\n",
    "\n",
    "hint: [Machine Learning Glossary](https://developers.google.com/machine-learning/glossary) (in case you don't remember the meaning of a certain ML term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "\n",
    "                 # verbose = False,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the parameters mean?\n",
    "- X: input values\n",
    "- y: output labels/values (classification/regression)\n",
    "- epochs: like the number of increments (forward-backward propagation)\n",
    "- batch_size: number of samples used (reduces computational effort instead of using all samples => stochastic gradient)\n",
    "- validation_split: portion of results used for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_accurs = pd.DataFrame(history.history)\n",
    "\n",
    "losses_accurs[['loss', 'val_loss']].plot()\n",
    "plt.title('Train and Test (val) Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()\n",
    "\n",
    "losses_accurs[['accuracy', 'val_accuracy']].plot()\n",
    "plt.title('Train and Test (val) Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can also get single elements through history.history.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predictions\n",
    "(Solution to our challenge)  \n",
    "Let's assume, we want to know, whether the point (0.5, -0.5) belongs to the upper or lower half moon.  \n",
    "We can predict this categorical problem with our just created model.  \n",
    "According to our X and y (see above), zeros belong to the upper half moon, ones to the lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[0.5, -0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Alternative model configuration with keras.layers\n",
    "\n",
    "\n",
    "Many many more layer options than what we are doing exist. \n",
    "\n",
    "Checkout https://www.tensorflow.org/api_docs/python/tf/keras/layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = Sequential([\n",
    "                 # in i/p shape ',' is necessary at end when you have only one dimension\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to save a model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save(\"model_moons.h5\")\n",
    "# here you can stop your notebook\n",
    "moons_model = load_model(\"model_moons.h5\")\n",
    "moons_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- We spoke about what a tensor is (n-dimensional array).  \n",
    "- We tried out several network parameters (activation functions, # layers/nodes, ...) in tensorflow playground.  \n",
    "- We learnt to know and used keras API to create a neural network model.  \n",
    "- We performed a challenge on the two half moon problem.\n",
    "- We saved and loaded the model for later use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "+ keras models api: https://keras.io/api/models/\n",
    "+ keras layers api: https://keras.io/api/layers/\n",
    "+ keras optimizer api: https://keras.io/api/optimizers/\n",
    "+ keras metrics api: https://keras.io/api/metrics/\n",
    "+ keras losses api: https://keras.io/api/losses/\n",
    "+ To track your different experiments on models use https://www.tensorflow.org/tensorboard/get_started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
